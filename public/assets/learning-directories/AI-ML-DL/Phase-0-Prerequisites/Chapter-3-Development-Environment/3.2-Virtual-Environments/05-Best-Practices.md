# 05 - Environment Best Practices

## üìã Introduction

Following best practices for virtual environment management ensures reproducible, maintainable, and professional ML projects. This guide covers strategies for organizing, managing, and optimizing environments across venv, conda, Poetry, and Docker.

---

## üéØ General Best Practices

### 1. One Environment Per Project

```bash
# ‚ùå Bad - Sharing environment across projects
project-a/
project-b/  # Both use ~/envs/shared-env
project-c/

# ‚úÖ Good - Isolated environments
project-a/
‚îú‚îÄ‚îÄ venv/
project-b/
‚îú‚îÄ‚îÄ venv/
project-c/
‚îú‚îÄ‚îÄ venv/
```

**Why?**
- Prevents dependency conflicts
- Easier debugging
- Independent version management
- Cleaner uninstallation

### 2. Never Commit Environments

```gitignore
# Always in .gitignore
venv/
env/
ENV/
.venv/
.conda/
.poetry/
```

**Reasons:**
- Large file sizes (hundreds of MBs)
- Platform-specific binaries
- Redundant with requirements files
- Slows down git operations

### 3. Document Dependencies

```bash
# venv
pip freeze > requirements.txt

# conda
conda env export > environment.yml
conda env export --from-history > environment.yml  # Cleaner

# Poetry
# Automatically maintained in pyproject.toml and poetry.lock
```

### 4. Use Version Control for Configuration

```
‚úÖ Commit:
- requirements.txt
- environment.yml
- pyproject.toml
- poetry.lock
- Dockerfile
- docker-compose.yml
- .python-version

‚ùå Don't commit:
- venv/
- .conda/
- __pycache__/
- *.pyc
```

### 5. Pin Critical Dependencies

```txt
# requirements.txt

# ‚ùå Unpinned - Can break
tensorflow
numpy
pandas

# ‚ö†Ô∏è Loose - Better but can still break
tensorflow>=2.0
numpy~=1.24
pandas>=2.0,<3.0

# ‚úÖ Pinned - Reproducible
tensorflow==2.13.0
numpy==1.24.3
pandas==2.0.3
```

---

## üèóÔ∏è Project Structure

### Recommended Directory Layout

```
ml-project/
‚îú‚îÄ‚îÄ .git/                    # Git repository
‚îú‚îÄ‚îÄ .gitignore              # Ignore venv, data, etc.
‚îú‚îÄ‚îÄ venv/                   # Virtual environment (not committed)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ data/                   # Data files
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep           # Track empty dirs
‚îú‚îÄ‚îÄ notebooks/              # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01-exploration.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 02-modeling.ipynb
‚îú‚îÄ‚îÄ src/                    # Source code
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py
‚îú‚îÄ‚îÄ tests/                  # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ test_preprocessing.py
‚îú‚îÄ‚îÄ models/                 # Saved models
‚îÇ   ‚îî‚îÄ‚îÄ best_model.pkl
‚îú‚îÄ‚îÄ results/                # Outputs
‚îÇ   ‚îú‚îÄ‚îÄ figures/
‚îÇ   ‚îî‚îÄ‚îÄ reports/
‚îú‚îÄ‚îÄ requirements.txt        # Dependencies
‚îú‚îÄ‚îÄ setup.py               # Package setup (optional)
‚îú‚îÄ‚îÄ README.md              # Documentation
‚îî‚îÄ‚îÄ .env                   # Environment variables (not committed)
```

### Comprehensive .gitignore

```gitignore
# Virtual Environments
venv/
env/
ENV/
.venv/
.conda/
.poetry/

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Jupyter
.ipynb_checkpoints/
*.ipynb

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# Data
data/raw/*
data/processed/*
!data/.gitkeep
*.csv
*.h5
*.hdf5
*.pkl
*.pickle

# Models
models/*.pth
models/*.h5
models/*.pkl
!models/.gitkeep

# Logs
logs/
*.log

# Environment
.env
.env.local

# OS
.DS_Store
Thumbs.db
```

---

## üì¶ Choosing the Right Tool

### Decision Tree

```
Start
‚îÇ
‚îú‚îÄ Simple Python project? ‚Üí venv
‚îÇ
‚îú‚îÄ Need specific Python version? ‚Üí conda or pyenv + venv
‚îÇ
‚îú‚îÄ Data science with C/C++ deps? ‚Üí conda
‚îÇ
‚îú‚îÄ Need GPU libraries (CUDA)? ‚Üí conda or Docker
‚îÇ
‚îú‚îÄ Modern project management? ‚Üí Poetry
‚îÇ
‚îú‚îÄ Deployment to production? ‚Üí Docker
‚îÇ
‚îî‚îÄ Team collaboration with lock files? ‚Üí Poetry or conda + lock
```

### Use Cases

**venv:**
- ‚úÖ Web applications (Flask, Django)
- ‚úÖ Simple scripts
- ‚úÖ Learning Python
- ‚úÖ Lightweight CLI tools

**conda:**
- ‚úÖ Data science projects
- ‚úÖ Scientific computing
- ‚úÖ Projects needing non-Python libraries
- ‚úÖ GPU development (CUDA)
- ‚úÖ Multiple Python versions

**Poetry:**
- ‚úÖ Modern Python applications
- ‚úÖ Package development
- ‚úÖ Projects with complex dependencies
- ‚úÖ Need for lock files
- ‚úÖ Team projects

**Docker:**
- ‚úÖ Production deployment
- ‚úÖ Microservices
- ‚úÖ Complex system dependencies
- ‚úÖ Sharing complete environments
- ‚úÖ CI/CD pipelines

---

## üîÑ Workflow Patterns

### Pattern 1: venv + pip

```bash
# Setup
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Development
pip install new-package
pip freeze > requirements.txt

# Share
git add requirements.txt
git commit -m "Add new-package"

# Reproduce
git clone repo
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Pattern 2: conda

```bash
# Setup
conda create -n project python=3.10
conda activate project
conda install --file requirements.txt

# Development
conda install new-package
conda env export --from-history > environment.yml

# Share
git add environment.yml
git commit -m "Add new-package"

# Reproduce
git clone repo
conda env create -f environment.yml
conda activate project
```

### Pattern 3: Poetry

```bash
# Setup
poetry new project
cd project
poetry install

# Development
poetry add new-package
# pyproject.toml and poetry.lock auto-updated

# Share
git add pyproject.toml poetry.lock
git commit -m "Add new-package"

# Reproduce
git clone repo
cd repo
poetry install  # Uses poetry.lock
```

### Pattern 4: Docker

```bash
# Setup
# Create Dockerfile
docker build -t project:latest .

# Development
# Edit Dockerfile
docker build -t project:latest .

# Share
git add Dockerfile
git commit -m "Update dependencies"

# Reproduce
git clone repo
docker build -t project:latest .
docker run project:latest
```

---

## üß™ Testing Environments

### Environment Verification Script

```python
# verify_env.py
import sys
import subprocess
from pathlib import Path

def verify_environment():
    """Verify virtual environment setup"""
    
    print("=" * 60)
    print("ENVIRONMENT VERIFICATION")
    print("=" * 60)
    
    # Check Python version
    print(f"\n‚úì Python: {sys.version}")
    required_version = (3, 10)
    if sys.version_info >= required_version:
        print(f"  ‚úÖ Version OK (>= {required_version[0]}.{required_version[1]})")
    else:
        print(f"  ‚ùå Version too old (need >= {required_version[0]}.{required_version[1]})")
        return False
    
    # Check virtual environment
    in_venv = (
        hasattr(sys, 'real_prefix') or 
        (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)
    )
    print(f"\n‚úì Virtual Environment: {'Yes' if in_venv else 'No'}")
    if not in_venv:
        print("  ‚ö†Ô∏è  Not in a virtual environment")
    
    # Check required packages
    required_packages = [
        'numpy',
        'pandas',
        'scikit-learn',
        'matplotlib',
    ]
    
    print(f"\n‚úì Required Packages:")
    all_installed = True
    for package in required_packages:
        try:
            __import__(package)
            version = __import__(package).__version__
            print(f"  ‚úÖ {package}: {version}")
        except ImportError:
            print(f"  ‚ùå {package}: NOT INSTALLED")
            all_installed = False
    
    # Check optional packages
    optional_packages = ['torch', 'tensorflow']
    print(f"\n‚úì Optional Packages:")
    for package in optional_packages:
        try:
            __import__(package)
            version = __import__(package).__version__
            print(f"  ‚úÖ {package}: {version}")
        except ImportError:
            print(f"  ‚ö†Ô∏è  {package}: not installed")
    
    # Check GPU availability
    print(f"\n‚úì GPU Support:")
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        if cuda_available:
            print(f"  ‚úÖ PyTorch CUDA: {torch.version.cuda}")
            print(f"     Devices: {torch.cuda.device_count()}")
        else:
            print(f"  ‚ö†Ô∏è  PyTorch CUDA: not available")
    except ImportError:
        print(f"  ‚ö†Ô∏è  PyTorch: not installed")
    
    try:
        import tensorflow as tf
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"  ‚úÖ TensorFlow GPU: {len(gpus)} device(s)")
        else:
            print(f"  ‚ö†Ô∏è  TensorFlow GPU: not available")
    except ImportError:
        print(f"  ‚ö†Ô∏è  TensorFlow: not installed")
    
    print("\n" + "=" * 60)
    return all_installed

if __name__ == "__main__":
    success = verify_environment()
    sys.exit(0 if success else 1)
```

**Usage:**
```bash
python verify_env.py
```

---

## üöÄ Performance Optimization

### 1. Use Fast Package Installers

```bash
# Use pip with binary wheels
pip install --only-binary :all: numpy

# Use mamba instead of conda
conda install mamba -c conda-forge
mamba install numpy pandas

# Use pip compile for faster resolution
pip install pip-tools
pip-compile requirements.in
pip-sync requirements.txt
```

### 2. Cache Dependencies

```bash
# pip cache
pip install --cache-dir ~/.pip_cache numpy

# conda cache
conda clean --all  # Clean occasionally
conda config --set always_yes yes  # Skip confirmations

# Poetry cache
poetry config cache-dir ~/.poetry_cache
```

### 3. Use Constraints Files

```txt
# constraints.txt
numpy<2.0
tensorflow>=2.0,<3.0

# Install with constraints
pip install -c constraints.txt -r requirements.txt
```

---

## üîê Security Best Practices

### 1. Pin Package Versions

```txt
# requirements.txt
numpy==1.24.3  # Specific version
tensorflow==2.13.0
scikit-learn==1.3.0
```

### 2. Use Hash Checking

```bash
# Generate hashes
pip freeze > requirements.txt
pip hash numpy==1.24.3 >> requirements.txt

# Install with hash verification
pip install --require-hashes -r requirements.txt
```

### 3. Scan for Vulnerabilities

```bash
# Using Safety
pip install safety
safety check

# Using pip-audit
pip install pip-audit
pip-audit

# Docker image scanning
docker scan ml-project:latest
```

### 4. Don't Store Secrets in Code

```python
# ‚ùå Bad - Hardcoded secrets
API_KEY = "sk-abc123..."

# ‚úÖ Good - Environment variables
import os
API_KEY = os.getenv("API_KEY")

# ‚úÖ Better - .env file (not committed)
from dotenv import load_dotenv
load_dotenv()
API_KEY = os.getenv("API_KEY")
```

---

## üìù Documentation

### README.md Template

```markdown
# Project Name

## Overview
Brief description of the project.

## Setup

### Prerequisites
- Python 3.10+
- (Optional) CUDA 11.8+ for GPU support

### Installation

1. Clone the repository:
\`\`\`bash
git clone https://github.com/username/project.git
cd project
\`\`\`

2. Create virtual environment:
\`\`\`bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate  # Windows
\`\`\`

3. Install dependencies:
\`\`\`bash
pip install -r requirements.txt
\`\`\`

## Usage

### Training
\`\`\`bash
python src/train.py --config configs/default.yaml
\`\`\`

### Evaluation
\`\`\`bash
python src/evaluate.py --model models/best_model.pkl
\`\`\`

## Project Structure
\`\`\`
project/
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ src/
‚îú‚îÄ‚îÄ models/
‚îî‚îÄ‚îÄ requirements.txt
\`\`\`

## License
MIT
```

---

## üéì Checklist

### Development Environment Setup

- [ ] Virtual environment created
- [ ] Dependencies installed
- [ ] requirements.txt/environment.yml created
- [ ] .gitignore configured
- [ ] IDE configured
- [ ] Git initialized
- [ ] README.md created
- [ ] verify_env.py passes

### Before Committing

- [ ] Code formatted (black, isort)
- [ ] Tests passing
- [ ] No sensitive data in code
- [ ] Dependencies documented
- [ ] .gitignore updated

### Before Sharing/Deploying

- [ ] Dependencies pinned
- [ ] Documentation complete
- [ ] Tests comprehensive
- [ ] Security audit passed
- [ ] Environment reproducible

---

## üéØ Key Takeaways

1. ‚úÖ **One environment per project** - Isolation is key
2. ‚úÖ **Never commit environments** - Use configuration files
3. ‚úÖ **Document dependencies** - requirements.txt, environment.yml, etc.
4. ‚úÖ **Pin versions** - Reproducibility and security
5. ‚úÖ **Choose right tool** - venv, conda, Poetry, or Docker
6. ‚úÖ **Test environment** - Verification scripts
7. ‚úÖ **Optimize performance** - Fast installers, caching
8. ‚úÖ **Security first** - Scan, hash-check, no secrets

---

## üîó Navigation

- **Up**: [3.2 Virtual Environments Overview](./README.md)
- **Previous**: [04 - Docker Containers](./04-Docker-Containers.md)
- **Next**: [06 - Sharing Environments](./06-Sharing-Environments.md)

---

**Remember:** Good environment management practices lead to reproducible, maintainable, and professional ML projects!
