# 03. Other Asymptotic Notations

## ğŸ¯ Beyond Big-O

While **Big-O** is the most commonly used notation, there are other asymptotic notations that provide different perspectives on algorithm complexity:

- **Big-O (O)** - Upper bound (worst case)
- **Big-Omega (Î©)** - Lower bound (best case)
- **Big-Theta (Î˜)** - Tight bound (both upper and lower)
- **Little-o (o)** - Strict upper bound
- **Little-omega (Ï‰)** - Strict lower bound

---

## ğŸ“ˆ Big-Omega (Î©) - Lower Bound

### Definition

**Big-Omega** describes the **best-case** or **minimum growth rate** of an algorithm.

**Formal Definition:**

An algorithm is **Î©(g(n))** if there exist positive constants **c** and **nâ‚€** such that:

$$
f(n) \geq c \cdot g(n) \text{ for all } n \geq n_0
$$

**In Plain English:**

The algorithm will take **at least** this much time, no matter how lucky we get.

### Example: Linear Search

```python
def linear_search(arr, target):
    for i in range(len(arr)):
        if arr[i] == target:
            return i
    return -1
```

**Analysis:**
- **Best case:** Target is at index 0 â†’ 1 comparison â†’ **Î©(1)**
- **Worst case:** Target is at the end or not present â†’ n comparisons â†’ **O(n)**

**Omega Notation:** Î©(1)  
**Big-O Notation:** O(n)

### When to Use Omega

- Describing **best-case** performance
- Proving a problem requires **at least** certain time
- Lower bounds on algorithms (e.g., "Sorting requires Î©(n log n) comparisons")

---

## ğŸ¯ Big-Theta (Î˜) - Tight Bound

### Definition

**Big-Theta** describes when **both the upper and lower bounds are the same**. It's the most precise notation.

**Formal Definition:**

An algorithm is **Î˜(g(n))** if it is both **O(g(n))** and **Î©(g(n))**.

$$
c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n) \text{ for all } n \geq n_0
$$

**In Plain English:**

The algorithm's performance is **exactly** this growth rate, regardless of input.

### Example: Finding Maximum

```python
def find_max(arr):
    max_val = arr[0]
    for i in range(1, len(arr)):
        if arr[i] > max_val:
            max_val = arr[i]
    return max_val
```

**Analysis:**
- **Best case:** Maximum at index 0 â†’ Still checks all n elements â†’ Î©(n)
- **Worst case:** Maximum at the end â†’ Checks all n elements â†’ O(n)
- **Every case:** Always checks all n elements

**Theta Notation:** Î˜(n)

This is the **most accurate** description because the algorithm **always** takes linear time.

### When to Use Theta

- When best and worst cases have the **same complexity**
- Describing the **exact** growth rate
- Most academic papers use Theta for precision

---

## ğŸ” Comparing the Three Main Notations

### Visual Representation

```
Operations
    |
    |     O(n)     â† Upper bound (Big-O)
    |    ----
    |   /    \
    |  |  Î˜(n)  |  â† Tight bound (Big-Theta)
    |   \    /
    |    ----
    |     Î©(n)     â† Lower bound (Big-Omega)
    |_________________ Input Size (n)
```

### Real-World Example: Bubble Sort

```python
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        swapped = False
        for j in range(n - i - 1):
            if arr[j] > arr[j + 1]:
                arr[j], arr[j + 1] = arr[j + 1], arr[j]
                swapped = True
        if not swapped:
            break
    return arr
```

**Analysis:**

| Case | Scenario | Complexity | Notation |
|------|----------|------------|----------|
| Best | Already sorted | n passes, no swaps | Î©(n) |
| Worst | Reverse sorted | nÂ² comparisons | O(nÂ²) |
| Average | Random order | ~nÂ²/2 comparisons | Î˜(nÂ²) |

**Summary:**
- **Big-O:** O(nÂ²) - worst case
- **Big-Omega:** Î©(n) - best case
- **Big-Theta:** Î˜(nÂ²) - average/typical case

---

## ğŸ”¬ Little-o (o) - Strict Upper Bound

### Definition

**Little-o** is like Big-O, but **strictly less than**.

**Formal Definition:**

f(n) is **o(g(n))** if:

$$
\lim_{n \to \infty} \frac{f(n)}{g(n)} = 0
$$

**In Plain English:**

f(n) grows **strictly slower** than g(n).

### Examples

âœ… **n is o(nÂ²)**
```
lim (n/nÂ²) = lim (1/n) = 0
nâ†’âˆ         nâ†’âˆ
```

âœ… **n log n is o(nÂ²)**
```
lim (n log n / nÂ²) = lim (log n / n) = 0
nâ†’âˆ                  nâ†’âˆ
```

âŒ **n is NOT o(n)**
```
lim (n/n) = 1 (not 0)
nâ†’âˆ
```

âŒ **nÂ² is NOT o(nÂ²)**
```
lim (nÂ²/nÂ²) = 1 (not 0)
nâ†’âˆ
```

### When to Use Little-o

- Rarely used in practice
- Academic papers for strict comparisons
- Proving one algorithm is **strictly better** than another

---

## ğŸ”¬ Little-omega (Ï‰) - Strict Lower Bound

### Definition

**Little-omega** is like Big-Omega, but **strictly greater than**.

**Formal Definition:**

f(n) is **Ï‰(g(n))** if:

$$
\lim_{n \to \infty} \frac{f(n)}{g(n)} = \infty
$$

**In Plain English:**

f(n) grows **strictly faster** than g(n).

### Examples

âœ… **nÂ² is Ï‰(n)**
```
lim (nÂ²/n) = lim (n) = âˆ
nâ†’âˆ         nâ†’âˆ
```

âœ… **nÂ² is Ï‰(n log n)**

âŒ **n is NOT Ï‰(n)**

### When to Use Little-omega

- Even rarer than little-o
- Theoretical computer science
- Proving lower bounds strictly

---

## ğŸ“Š Notation Comparison Table

| Notation | Name | Meaning | Math Analogy | Common Use |
|----------|------|---------|--------------|------------|
| O(g(n)) | Big-O | Upper bound | â‰¤ | Worst case |
| Î©(g(n)) | Big-Omega | Lower bound | â‰¥ | Best case |
| Î˜(g(n)) | Big-Theta | Tight bound | = | Exact growth |
| o(g(n)) | Little-o | Strict upper | < | Rare |
| Ï‰(g(n)) | Little-omega | Strict lower | > | Very rare |

---

## ğŸ¨ Practical Examples

### Example 1: Merge Sort

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    
    return merge(left, right)
```

**Analysis:**
- **Best case:** Î©(n log n) - Still divides and merges
- **Worst case:** O(n log n) - Always divides and merges
- **Tight bound:** Î˜(n log n) - Always same complexity

**Best Description:** Î˜(n log n)

### Example 2: Quick Sort

```python
def quick_sort(arr):
    if len(arr) <= 1:
        return arr
    
    pivot = arr[len(arr) // 2]
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    
    return quick_sort(left) + middle + quick_sort(right)
```

**Analysis:**
- **Best case:** Î©(n log n) - Perfect pivot selection
- **Worst case:** O(nÂ²) - Pivot is always min/max
- **Average case:** Î˜(n log n) - Random pivots

**Descriptions:**
- O(nÂ²) for worst case
- Î©(n log n) for best case
- Î˜(n log n) for average case (with random pivots)

### Example 3: Binary Search

```python
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    
    return -1
```

**Analysis:**
- **Best case:** Î©(1) - Target at middle
- **Worst case:** O(log n) - Target at leaf or not present
- **Average case:** Î˜(log n)

**Most Common Description:** O(log n)

---

## ğŸ§  Which Notation Should You Use?

### In Practice (Industry)

**Use Big-O (O)** 95% of the time:
- Interviews ask "What's the Big-O?"
- Documentation uses Big-O
- Most useful for comparing algorithms

### In Academia

**Use Big-Theta (Î˜)** when possible:
- More precise
- Shows exact growth rate
- Standard in research papers

### General Guidelines

| Situation | Use |
|-----------|-----|
| Describing worst-case | Big-O |
| Describing best-case | Big-Omega |
| Describing exact complexity | Big-Theta |
| Comparing algorithms | Big-O (usually) |
| Theoretical bounds | All notations |

---

## ğŸ‹ï¸ Practice Problems

### Problem 1: Identify the Notation

For this algorithm, determine O, Î©, and Î˜:

```python
def count_elements(arr):
    count = 0
    for item in arr:
        count += 1
    return count
```

<details>
<summary>Solution</summary>

**Analysis:**
- Always loops n times
- Best case: n operations
- Worst case: n operations

**Answer:**
- O(n) - Upper bound
- Î©(n) - Lower bound
- Î˜(n) - Tight bound (best description)
</details>

### Problem 2: Best vs Worst

For insertion sort, determine Big-O and Big-Omega:

```python
def insertion_sort(arr):
    for i in range(1, len(arr)):
        key = arr[i]
        j = i - 1
        while j >= 0 and arr[j] > key:
            arr[j + 1] = arr[j]
            j -= 1
        arr[j + 1] = key
```

<details>
<summary>Solution</summary>

**Best case (sorted array):**
- Inner while never runs
- Just n passes
- Î©(n)

**Worst case (reverse sorted):**
- Inner while runs i times for each i
- Total: 1 + 2 + 3 + ... + n = nÂ²/2
- O(nÂ²)

**Answer:**
- O(nÂ²) - Worst case
- Î©(n) - Best case
- No Theta (best â‰  worst)
</details>

### Problem 3: True or False?

1. If f(n) = Î˜(nÂ²), then f(n) = O(nÂ²) âœ“ or âœ—
2. If f(n) = O(nÂ²), then f(n) = Î˜(nÂ²) âœ“ or âœ—
3. If f(n) = O(n) and f(n) = Î©(n), then f(n) = Î˜(n) âœ“ or âœ—
4. O(n) and Î©(nÂ²) is possible âœ“ or âœ—
5. Î˜(n) means exactly n operations âœ“ or âœ—

<details>
<summary>Answers</summary>

1. âœ“ (Theta implies Big-O)
2. âœ— (O is upper bound only, might be less)
3. âœ“ (Definition of Theta)
4. âœ— (Contradictory: lower bound > upper bound)
5. âœ— (Means linear growth, could be 3n or 100n)
</details>

---

## ğŸ¯ Key Takeaways

1. âœ… **Big-O (O)** - Upper bound, worst case, most commonly used
2. âœ… **Big-Omega (Î©)** - Lower bound, best case
3. âœ… **Big-Theta (Î˜)** - Tight bound, exact growth rate
4. âœ… **Little-o, Little-omega** - Strict bounds, rarely used
5. âœ… In practice, use **Big-O**; in academia, prefer **Theta**

### Quick Decision Tree

```
Is best case = worst case?
â”œâ”€ YES â†’ Use Î˜(n) (most precise)
â””â”€ NO
   â”œâ”€ Describing worst case? â†’ Use O(n)
   â””â”€ Describing best case? â†’ Use Î©(n)
```

---

## ğŸš€ What's Next?

Now that you understand all asymptotic notations, let's dive deep into **Time Complexity Analysis** with practical techniques for analyzing real code!

---

[â† Previous: Big-O Notation](./02-Big-O-Notation.md) | [Back to README](./README.md) | [Next: Time Complexity Analysis â†’](./04-Time-Complexity-Analysis.md)
