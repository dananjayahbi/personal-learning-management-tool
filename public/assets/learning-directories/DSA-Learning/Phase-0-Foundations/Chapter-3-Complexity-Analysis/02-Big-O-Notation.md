# 02. Big-O Notation

## ğŸ¯ What is Big-O Notation?

**Big-O Notation** is a mathematical way to describe how an algorithm's performance scales with input size. It gives us the **upper bound** (worst case) of an algorithm's growth rate.

Think of Big-O as answering: **"In the worst case, how does this algorithm scale?"**

### The "O" Symbol

The **O** stands for "**Order of**" (as in "order of magnitude").

When we write **O(n)**, we say:
- "**Big-O of n**" or
- "**Order n**" or
- "**Linear complexity**"

---

## ğŸ§® Formal Definition

**Mathematical Definition:**

An algorithm is **O(g(n))** if there exist positive constants **c** and **nâ‚€** such that:

$$
f(n) \leq c \cdot g(n) \text{ for all } n \geq n_0
$$

**In Plain English:**

After some point (nâ‚€), the function f(n) (actual operations) is always less than or equal to some constant times g(n) (our Big-O function).

### Visual Example

```
Operations
    |
    |           f(n) = 3n + 5
    |          /
    |         /
    |        / cÂ·g(n) = 4n
    |       /  
    |______/_____________ Input Size (n)
           nâ‚€
```

After nâ‚€, f(n) stays below cÂ·g(n), so f(n) is O(n).

---

## ğŸ” How to Calculate Big-O

### Step-by-Step Method

**Step 1:** Count all operations as a function of n  
**Step 2:** Keep only the **highest order term**  
**Step 3:** Drop the **constant coefficient**  
**Step 4:** Express as O(...)

### Example 1: Simple Function

```python
def example1(arr):
    n = len(arr)           # 1 operation
    total = 0              # 1 operation
    
    for i in range(n):     # n iterations
        total += arr[i]    # 1 operation per iteration
    
    return total           # 1 operation

# Total: 1 + 1 + n + 1 = n + 3
```

**Calculation:**
- Total operations: f(n) = n + 3
- Highest order term: n
- Drop constant: n
- **Big-O: O(n)**

### Example 2: Nested Loops

```python
def example2(arr):
    n = len(arr)
    for i in range(n):           # n iterations
        for j in range(n):       # n iterations for each i
            print(arr[i], arr[j]) # 1 operation
    
# Total: n Ã— n Ã— 1 = nÂ²
```

**Calculation:**
- Total operations: f(n) = nÂ²
- Highest order term: nÂ²
- **Big-O: O(nÂ²)**

### Example 3: Multiple Terms

```python
def example3(arr):
    n = len(arr)
    
    # First loop
    for i in range(n):      # n iterations
        print(arr[i])
    
    # Second loop
    for i in range(n):      # n iterations
        for j in range(n):  # n iterations
            print(i, j)
    
    # Third loop
    for i in range(100):    # 100 iterations
        print(i)

# Total: n + nÂ² + 100
```

**Calculation:**
- Total operations: f(n) = nÂ² + n + 100
- Highest order term: nÂ²
- Drop constants and lower terms: nÂ²
- **Big-O: O(nÂ²)**

---

## ğŸ“ Big-O Rules and Properties

### Rule 1: Drop Constants

**Constants don't matter in Big-O.**

```python
# O(2n) = O(n)
def double_loop(arr):
    for i in arr:
        print(i)
    for i in arr:
        print(i)
# O(n) + O(n) = O(2n) = O(n)

# O(n/2) = O(n)
def half_loop(arr):
    for i in range(len(arr) // 2):
        print(arr[i])
# O(n)
```

**Why?** For large n, 2n and n grow at the same rate.

### Rule 2: Drop Lower Order Terms

**Only keep the dominant (fastest-growing) term.**

| Expression | Simplified |
|------------|------------|
| O(nÂ² + n) | O(nÂ²) |
| O(nÂ³ + nÂ² + n) | O(nÂ³) |
| O(n + log n) | O(n) |
| O(n log n + n) | O(n log n) |
| O(2â¿ + nÂ²) | O(2â¿) |

**Why?** For large n, nÂ² dominates n. Example:
- n = 1000: nÂ² = 1,000,000 vs n = 1,000
- nÂ² is 1000Ã— larger!

### Rule 3: Different Inputs = Different Variables

**Use different variables for different inputs.**

```python
# WRONG: O(n)
def process_two_arrays(arr1, arr2):
    for item in arr1:
        print(item)
    for item in arr2:
        print(item)

# CORRECT: O(a + b)
# where a = len(arr1), b = len(arr2)
```

### Rule 4: Arithmetic Series

```python
# Sum: 1 + 2 + 3 + ... + n = n(n+1)/2
for i in range(n):
    for j in range(i):
        print(i, j)

# Total operations: 1 + 2 + 3 + ... + n = nÂ²/2
# Big-O: O(nÂ²)
```

### Rule 5: Logarithms

**Whenever you divide n repeatedly, think O(log n).**

```python
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1

# Each iteration cuts search space in half
# n â†’ n/2 â†’ n/4 â†’ n/8 â†’ ... â†’ 1
# Number of iterations: logâ‚‚(n)
# Big-O: O(log n)
```

---

## ğŸ¨ Common Big-O Examples

### O(1) - Constant Time

**Operations that don't depend on input size.**

```python
def get_first(arr):
    return arr[0]  # Always 1 operation

def add_numbers(a, b):
    return a + b   # Always 1 operation

def hash_lookup(dictionary, key):
    return dictionary[key]  # Average: O(1)
```

### O(log n) - Logarithmic Time

**Dividing the problem in half repeatedly.**

```python
def binary_search(arr, target):
    left, right = 0, len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1
```

### O(n) - Linear Time

**One pass through the data.**

```python
def find_max(arr):
    max_val = arr[0]
    for num in arr:
        if num > max_val:
            max_val = num
    return max_val

def count_occurrences(arr, target):
    count = 0
    for num in arr:
        if num == target:
            count += 1
    return count
```

### O(n log n) - Linearithmic Time

**Efficient sorting algorithms.**

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])      # T(n/2)
    right = merge_sort(arr[mid:])     # T(n/2)
    
    return merge(left, right)         # O(n)

# Recurrence: T(n) = 2T(n/2) + O(n)
# Solution: O(n log n)
```

### O(nÂ²) - Quadratic Time

**Nested loops over the data.**

```python
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):           # n times
        for j in range(n-i-1):   # n times (average)
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr

def find_pairs(arr):
    pairs = []
    for i in range(len(arr)):
        for j in range(len(arr)):
            pairs.append((arr[i], arr[j]))
    return pairs
```

### O(2â¿) - Exponential Time

**Recursive algorithms with two recursive calls.**

```python
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# Each call makes 2 more calls
# Tree depth: n
# Total calls: 2â° + 2Â¹ + 2Â² + ... + 2â¿ â‰ˆ 2â¿
```

### O(n!) - Factorial Time

**Generating all permutations.**

```python
def generate_permutations(arr):
    if len(arr) <= 1:
        return [arr]
    
    perms = []
    for i in range(len(arr)):
        rest = arr[:i] + arr[i+1:]
        for perm in generate_permutations(rest):
            perms.append([arr[i]] + perm)
    return perms

# n choices Ã— (n-1) choices Ã— ... Ã— 1 choice = n!
```

---

## ğŸ“Š Complexity Comparison

### Growth Rates Table

For n = 1,000,000:

| Complexity | Operations | Practical? |
|------------|------------|------------|
| O(1) | 1 | âœ… Instant |
| O(log n) | ~20 | âœ… Instant |
| O(n) | 1,000,000 | âœ… Fast |
| O(n log n) | ~20,000,000 | âœ… Fast |
| O(nÂ²) | 1,000,000,000,000 | âŒ Slow |
| O(2â¿) | 2^1000000 | âŒ Impossible |
| O(n!) | 1000000! | âŒ Impossible |

### Visual Comparison

```
Operations
    |                                          O(n!)
    |                                     O(2â¿)
    |                                O(nÂ²)
    |                           O(n log n)
    |                      O(n)
    |              O(log n)
    |________O(1)_________________________ Input Size (n)
```

---

## ğŸ‹ï¸ Practice Problems

### Problem 1: Analyze This Code

```python
def mystery1(n):
    result = 0
    for i in range(n):
        result += i
    for i in range(n):
        for j in range(n):
            result += i * j
    return result
```

<details>
<summary>Solution</summary>

**Analysis:**
- First loop: O(n)
- Second loop: O(nÂ²)
- Total: O(n) + O(nÂ²) = O(nÂ²)

**Answer: O(nÂ²)**
</details>

### Problem 2: What's the Complexity?

```python
def mystery2(n):
    i = 1
    while i < n:
        print(i)
        i *= 2
```

<details>
<summary>Solution</summary>

**Analysis:**
- i doubles each iteration: 1, 2, 4, 8, 16, ...
- After k iterations: i = 2^k
- Loop stops when 2^k â‰¥ n
- So k = logâ‚‚(n)

**Answer: O(log n)**
</details>

### Problem 3: Multiple Inputs

```python
def mystery3(arr1, arr2):
    for item in arr1:
        print(item)
    
    for item1 in arr1:
        for item2 in arr2:
            print(item1, item2)
```

<details>
<summary>Solution</summary>

Let a = len(arr1), b = len(arr2)

**Analysis:**
- First loop: O(a)
- Second loop: O(a Ã— b)
- Total: O(a + aÃ—b) = O(aÃ—b) [dominant term]

**Answer: O(a Ã— b)**
</details>

### Problem 4: Recursive Function

```python
def mystery4(n):
    if n <= 1:
        return 1
    return mystery4(n-1) + mystery4(n-1)
```

<details>
<summary>Solution</summary>

**Analysis:**
- Each call makes 2 recursive calls
- Tree depth: n
- Total calls: 2â¿

**Answer: O(2â¿)**

*Note: This is similar to Fibonacci but even less efficient!*
</details>

---

## âœï¸ Exercises

### Exercise 1: Simplify These

Simplify to proper Big-O notation:

1. O(5n + 100)
2. O(nÂ² + 2n + 1)
3. O(3nÂ³ + 2nÂ² + n)
4. O(log n + n)
5. O(2â¿ + nÂ³)

<details>
<summary>Answers</summary>

1. O(n)
2. O(nÂ²)
3. O(nÂ³)
4. O(n)
5. O(2â¿)
</details>

### Exercise 2: Rank by Speed

Rank these from fastest to slowest:

- O(n!)
- O(1)
- O(nÂ²)
- O(n log n)
- O(2â¿)
- O(log n)
- O(n)

<details>
<summary>Answer (Fastest to Slowest)</summary>

1. O(1)
2. O(log n)
3. O(n)
4. O(n log n)
5. O(nÂ²)
6. O(2â¿)
7. O(n!)
</details>

### Exercise 3: True or False?

1. O(2n) = O(n) âœ“ or âœ—
2. O(n + log n) = O(n) âœ“ or âœ—
3. O(nÂ²) is faster than O(n log n) âœ“ or âœ—
4. O(n) + O(nÂ²) = O(nÂ² + n) âœ“ or âœ—
5. Constants matter in Big-O âœ“ or âœ—

<details>
<summary>Answers</summary>

1. âœ“ (Drop constants)
2. âœ“ (Drop lower order terms)
3. âœ— (O(n log n) is faster)
4. âœ“ (But simplifies to O(nÂ²))
5. âœ— (Constants are dropped)
</details>

---

## ğŸ¯ Key Takeaways

1. âœ… Big-O describes the **upper bound** of growth rate
2. âœ… Drop **constants** and **lower order terms**
3. âœ… Use **different variables** for different inputs
4. âœ… Common complexities: O(1), O(log n), O(n), O(n log n), O(nÂ²), O(2â¿), O(n!)
5. âœ… Focus on **worst-case** behavior
6. âœ… Big-O is about **scalability**, not exact time

### Quick Reference Card

```
O(1)       < O(log n) < O(n) < O(n log n) < O(nÂ²) < O(2â¿) < O(n!)
Constant     Logarithmic  Linear  Linearithmic  Quadratic  Exponential  Factorial
```

---

## ğŸš€ What's Next?

Now you understand Big-O! Next, we'll explore other asymptotic notations:
- **Big-Omega (Î©)** - Lower bound
- **Big-Theta (Î˜)** - Tight bound
- When to use each

---

[â† Previous: Introduction](./01-Introduction-to-Complexity.md) | [Back to README](./README.md) | [Next: Other Notations â†’](./03-Other-Notations.md)
